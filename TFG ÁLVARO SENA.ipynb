{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import sys\n",
    "from arch import arch_model\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from darts.models import TBATS\n",
    "from darts.metrics import mape\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from darts import TimeSeries\n",
    "\n",
    "excel= pd.read_excel(\"TFG.xlsx\", index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3595825",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4e4be",
   "metadata": {},
   "source": [
    "# COMPROBACIÓN MODELO LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de las acciones que queremos analizar y predecir\n",
    "df = excel[excel.index.year <= 2019]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una gráfica con el histórico de precios\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Histórico de precios')\n",
    "plt.plot(df['Close'], linewidth = 1)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Cierre USD ($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un nuevo DataFrame con únicamente la columna Close\n",
    "data = df.filter(['Close'])\n",
    "# Convertimos el dataframe en un numpy array\n",
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1586643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de filas para entrenar el modelo\n",
    "training_data_len = int(np.ceil( len(dataset) * .9))\n",
    "\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos y normalizamos los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d90584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos y normalizamos los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el data set para entrenamiento con los datos escalados\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Separamos los datos entre x_train y y_train\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db48ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos x_train y y_train en numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Cambiamos la forma de los datos\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da34df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Añadimos capas LSTM con 50 unidades\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "# Añadimos una capa densa con 25 unidades\n",
    "model.add(Dense(25))\n",
    "# Añadir una capa de salida densa con 1 unidad\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3425f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el conjunto de datos de prueba\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "# Creamos los conjuntos de datos x_test y y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a un numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Cambiamos la forma de los datos\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de las predicciones\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el RMSE\n",
    "rmse=np.sqrt(np.mean(((predictions- y_test)**2)))\n",
    "print(\"Root Mean Square Error:\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el MAE\n",
    "mae = np.mean(np.abs(predictions - y_test))\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c760c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el MAPE\n",
    "\n",
    "# Cambiamos formato\n",
    "y_test_mape = TimeSeries.from_values(y_test)\n",
    "predictions_mape = TimeSeries.from_values(predictions)\n",
    "\n",
    "# Calculamos MAPE\n",
    "mape_score = mape(y_test_mape, predictions_mape)\n",
    "mape_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el coeficiente de determinación (R cuadrado)\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"Coeficiente de determinación (R cuadrado):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los datos\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('NASDAQ')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'], linewidth = 1)\n",
    "plt.plot(valid[['Close', 'Predictions']], linewidth = 1)\n",
    "plt.legend(['Datos de entrenamiento', 'Datos de prueba', 'Predicciones'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrar los datos para el período desde el año 2020 hasta el final\n",
    "train_2020 = train[train.index.year >= 2019]\n",
    "valid_2020 = valid[valid.index.year >= 2019]\n",
    "\n",
    "# Crear la figura y establecer el tamaño\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# Título del gráfico\n",
    "plt.title('NASDAQ')\n",
    "\n",
    "# Etiqueta del eje x\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "\n",
    "# Etiqueta del eje y\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "\n",
    "# Tramar los datos de entrenamiento\n",
    "plt.plot(train_2020['Close'], linewidth=1)\n",
    "\n",
    "# Tramar los datos de prueba y las predicciones\n",
    "plt.plot(valid_2020[['Close', 'Predictions']], linewidth=1)\n",
    "\n",
    "# Agregar la leyenda\n",
    "plt.legend(['Datos de entrenamiento', 'Datos de prueba', 'Predicciones'], loc='lower right')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72481a",
   "metadata": {},
   "source": [
    "# MODELO LSTM EN EL COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de las acciones que queremos analizar y predecir\n",
    "df2 = excel[excel.index.year <= 2021]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un nuevo DataFrame con únicamente la columna Close\n",
    "data = df2.filter(['Close'])\n",
    "# Convertimos el dataframe en un numpy array\n",
    "dataset = data.values\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de filas para entrenar el modelo (cojo 82% de los datos para que llegue hasta 31-12-2019=Covid)\n",
    "training_data_len = int(np.ceil( len(dataset) * .82259767687434))\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f94f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos y normalizamos los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc19f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos y normalizamos los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadefa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el data set para entrenamiento con los datos escalados\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Separamos los datos entre x_train y y_train\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos x_train y y_train en numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Cambiamos la forma de los datos\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76779ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Añadimos capas LSTM con 50 unidades\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "# Añadimos una capa densa con 25 unidades\n",
    "model.add(Dense(25))\n",
    "# Añadir una capa de salida densa con 1 unidad\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el conjunto de datos de prueba\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "# Creamos los conjuntos de datos x_test y y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63932589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a un numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Cambiamos la forma de los datos\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be90cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de las predicciones\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions2 = pd.DataFrame(predictions)\n",
    "#Para pasarlo a excel: \n",
    "predictions2.to_excel('impacto_covid.xlsx', index=False)\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba295b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el MAE\n",
    "mae = np.mean(np.abs(predictions - y_test))\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9dde55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el coeficiente de determinación (R cuadrado)\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"Coeficiente de determinación (R cuadrado):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los datos\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('NASDAQ')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'], linewidth = 1)\n",
    "plt.plot(valid[['Close', 'Predictions']], linewidth = 1)\n",
    "plt.legend(['Datos de entrenamiento', 'Datos de prueba', 'Predicciones'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ac88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos solo el periodo que se predice\n",
    "#Filtrar los datos para el período desde el año 2021 hasta el final\n",
    "train_2020 = train[train.index.year >= 2020]\n",
    "valid_2020 = valid[valid.index.year >= 2020]\n",
    "\n",
    "# Crear la figura y establecer el tamaño\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# Título del gráfico\n",
    "plt.title('NASDAQ')\n",
    "\n",
    "# Etiqueta del eje x\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "\n",
    "# Etiqueta del eje y\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "\n",
    "# Tramar los datos de entrenamiento\n",
    "plt.plot(train_2020['Close'], linewidth=1)\n",
    "\n",
    "# Tramar los datos de prueba y las predicciones\n",
    "plt.plot(valid_2020[['Close', 'Predictions']], linewidth=1)\n",
    "\n",
    "# Agregar la leyenda\n",
    "plt.legend(['Datos de entrenamiento', 'Datos de prueba', 'Predicciones'], loc='lower right')\n",
    "\n",
    "# Guardar el Gráfico como jpg\n",
    "plt.savefig('grafico_Covid.jpg')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e684988",
   "metadata": {},
   "source": [
    "# MODELO LSTM EN LA GUERRA DE UCRANIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8724461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de las acciones que queremos analizar y predecir\n",
    "df3 = excel[excel.index.year <= 2023]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7eb591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un nuevo DataFrame con únicamente la columna Close\n",
    "data = df3.filter(['Close'])\n",
    "# Convertimos el dataframe en un numpy array\n",
    "dataset = data.values\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de filas para entrenar el modelo (cojo 85,6% de los datos para que llegue hasta 1-02-2022-Guerra Ucrania)\n",
    "training_data_len = int(np.ceil( len(dataset) * .85637342908))\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos y normalizamos los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos y normalizamos los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el data set para entrenamiento con los datos escalados\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Separamos los datos entre x_train y y_train\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb99bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos x_train y y_train en numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Cambiamos la forma de los datos\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc273052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Añadimos capas LSTM con 50 unidades\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "# Añadimos una capa densa con 25 unidades\n",
    "model.add(Dense(25))\n",
    "# Añadir una capa de salida densa con 1 unidad\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbca35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c37cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el conjunto de datos de prueba\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "# Creamos los conjuntos de datos x_test y y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a un numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Cambiamos la forma de los datos\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de las predicciones\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions2 = pd.DataFrame(predictions)\n",
    "# Para pasarlo a excel: \n",
    "predictions2.to_excel('impacto_guerra_Ucrania.xlsx', index=False)\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaaf1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el MAE\n",
    "mae = np.mean(np.abs(predictions - y_test))\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b173026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el coeficiente de determinación (R cuadrado)\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"Coeficiente de determinación (R cuadrado):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los datos\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Nasdaq')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'], linewidth = 1)\n",
    "plt.plot(valid[['Close', 'Predictions']], linewidth = 1)\n",
    "plt.legend(['Datos de entrenamiento', 'Datos de prueba', 'Predicciones'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos solo el periodo que se predice\n",
    "#Filtrar los datos para el período desde el año 2023 hasta el final\n",
    "train_2020 = train[train.index.year >= 2022]\n",
    "valid_2020 = valid[valid.index.year >= 2022]\n",
    "\n",
    "# Crear la figura y establecer el tamaño\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# Título del gráfico\n",
    "plt.title('NASDAQ')\n",
    "\n",
    "# Etiqueta del eje x\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "\n",
    "# Etiqueta del eje y\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "\n",
    "# Tramar los datos de entrenamiento\n",
    "plt.plot(train_2020['Close'], linewidth=1)\n",
    "\n",
    "# Tramar los datos de prueba y las predicciones\n",
    "plt.plot(valid_2020[['Close', 'Predictions']], linewidth=1)\n",
    "\n",
    "# Agregar la leyenda\n",
    "plt.legend(['Datos de entrenamiento', 'Datos de prueba', 'Predicciones'], loc='lower right')\n",
    "\n",
    "# Guardar el Gráfico como jpg\n",
    "plt.savefig('grafico_Ucrania.jpg')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5aadfd",
   "metadata": {},
   "source": [
    "# MODELO DE GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel=pd.read_excel('TFG.xlsx')\n",
    "excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el modelo con p=1 y q=1\n",
    "model=arch_model(excel['Rentabilidad'], vol='Garch', p=1, q=1)\n",
    "model_fit=model.fit(update_freq=5)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos los datos de volatilidad diaria con el modelo de Garch\n",
    "excel['volatility'] = model_fit.conditional_volatility\n",
    "print(excel[['Rentabilidad', 'volatility']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc439cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo pasamos a excel\n",
    "excel.to_excel('modelo_garch.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos los resultados\n",
    "excel['Fecha'] = pd.to_datetime(excel['Fecha'])\n",
    "excel.set_index('Fecha', inplace=True)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(excel.index,excel['volatility'])\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Volatilidad\")\n",
    "plt.title('Volatilidad Histórica')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig('grafico_garch.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "93.9844px",
    "width": "320px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
